{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Семинар 1 Индекс\n",
    "\n",
    "## Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### чтение файла \n",
    "- конструкция __with open__ (recommended)\n",
    "- конструкция __open + close__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fpath = 'fpath.txt'\n",
    "\n",
    "# одним массивом  \n",
    "with open(fpath, 'r') as f:  \n",
    "    text = f.read() \n",
    "\n",
    "#по строкам, в конце каждой строки \\n  \n",
    "with open(fpath, 'r') as f:   \n",
    "    text = f.readlines() \n",
    "\n",
    "#по строкам, без \\n   \n",
    "with open(fpath, 'r') as f:   \n",
    "    text = f.read().splitlines() \n",
    "    \n",
    "#not reccomended  \n",
    "file = open(txt_fpath, 'r')  \n",
    "text = file.read()    \n",
    "file.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### работа с файлами и папками"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### os.path  \n",
    "путь до файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# возвращает полный путь до папки/файла по имени файла / папки\n",
    "print(os.path.abspath('fpath.txt'))\n",
    "\n",
    "# возвращает имя файла / папки по полному пути до него\n",
    "print(os.path.basename('/your/path/to/folder/with/fpath.txt'))\n",
    "\n",
    "# проверить существование директории - True / False\n",
    "print(os.path.exists('your/path/to/any/folder/'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### os.listdir  \n",
    "возвращает список файлов в данной директории"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "main_dir = '/your/path/to/folder/with/folders/'\n",
    "os.listdir(main_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "сделаем пути абсолютными, чтобы наш код не зависел от того, где лежит этот файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[main_dir + fpath for fpath in os.listdir(main_dir)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "не забывайте исключать системные директории, такие как .DS_Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[main_dir + fpath for fpath in os.listdir(main_dir) if not '.DS_Store' in fpath]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### os.walk\n",
    "root - начальная директория  \n",
    "dirs - список поддиректорий (папок)   \n",
    "files - список файлов в этих поддиректориях  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "main_dir = '/your/path/to/folder/with/folders/'\n",
    "\n",
    "for root, dirs, files in os.walk(main_dir):\n",
    "    for name in files:\n",
    "        print(os.path.join(root, name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> __os.walk__ возвращает генератор, это значит, что получить его элементы можно только проитерировавшись по нему  \n",
    "но его легко можно превратить в list и увидеть все его значения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list(os.walk(main_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Обратный индекс \n",
    "\n",
    "Сам по себе обратный индекс не может осуществлять поиск, для этого необходимо добавить к нему определенную метрику. Это не совсем очевидная задача, поэтому немного отложим ее. А сейчас посмотрим, что полезного можно вытащить из индекса.    \n",
    "По сути, индекс - это информация о частоте встречаемости слова в каждом документе.   \n",
    "Из этого можно понять, например:\n",
    "1. какое слово является самым часто употребимым / редким\n",
    "2. какие слова встречаются всегда вместе. Так можно парсить твиттер, fb, форумы и отлавливать новые устойчивые выражения в речи\n",
    "3. какой документ является самым большим / маленьким (очень изощренный способ, когда есть _len_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Задача__: \n",
    "получите обратный индекс для коллекция документов.    \n",
    "Перед этим постройте матрицу терм-документ и сделайте функцию булева поиска, которая по запросу будет возвращать 5 релевантных документов.   \n",
    "В качестве коллекции возьмите сценарий сезонов сериала Друзья. Одна серия - один документ.\n",
    "\n",
    "[download_friends_corpus](https://yadi.sk/d/k_M7n63A3adGSz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этапы:   \n",
    "    1. получить коллекцию документов\n",
    "    2. для каждого файла коллекции сделать необходимую на ваш взгляд предобработку\n",
    "    3. получить матрицу терм-документ, написать функцию поиска по ней\n",
    "    4. получить обратный индекс в виде словаря, где ключ - нормализованное слово, \n",
    "    значение - список файлов, в которых это слово встречается\n",
    "    5. вывести кусочек индекса в виде таблицы \n",
    "    6. сделать анализ обратного индекса. Это задание принимается в виде кода и ответов на вопросы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Friends/wedding.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напоминание:    \n",
    "> При итерации по списку вы можете помимо самого элемента получить его порядковый номер    \n",
    "``` for i, element in enumerate(your_list): ...  ```    \n",
    "Иногда для получения элемента делают так -  ``` your_list[i] ```, старайтесь этого избегать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "main_dir = '/Users/irene/Downloads/IR/Friends'\n",
    "files_list = []\n",
    "\n",
    "### пройдитесь по всем папкам коллекции и соберите все пути .txt файлов\n",
    "### _check : в коллекции должно быть 165 файлов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for root, dirs, files in os.walk(main_dir):\n",
    "    for name in files:\n",
    "        if not '.DS_Store' in name:\n",
    "            files_list.append(os.path.join(root, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem\n",
    "m = Mystem()\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    text = re.sub('(www|http)\\S+', ' ', text)# чистит от ссылок\n",
    "    text = re.sub('\\n', ' ', text)\n",
    "    text = re.sub('[^\\w\\s]', ' ', text)\n",
    "    text = re.sub('[0-9]', ' ', text)\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lemmatize(text):\n",
    "    lemmas = m.lemmatize(text)\n",
    "    #text = re.sub(' +', ' ', \"\".join(lemmas))\n",
    "    return ' '.join([x for x in lemmas if x != ' '])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 165/165 [00:22<00:00,  7.41it/s]\n"
     ]
    }
   ],
   "source": [
    "lemmatized_texts = []\n",
    "for each_f in tqdm(files_list):\n",
    "    with open(each_f, 'r') as f:  \n",
    "        text = f.read()\n",
    "        lemmatized = lemmatize(clean(text))\n",
    "        lemmatized_texts.append(lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vec = CountVectorizer()\n",
    "X = vec.fit_transform(lemmatized_texts)\n",
    "df = pd.DataFrame(X.toarray(), columns=vec.get_feature_names())\n",
    "words = list(vec.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создаем датафрейм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>after</th>\n",
       "      <th>again</th>\n",
       "      <th>ahh</th>\n",
       "      <th>all</th>\n",
       "      <th>and</th>\n",
       "      <th>are</th>\n",
       "      <th>au</th>\n",
       "      <th>ban</th>\n",
       "      <th>bay</th>\n",
       "      <th>behind</th>\n",
       "      <th>...</th>\n",
       "      <th>ярмарка</th>\n",
       "      <th>ярость</th>\n",
       "      <th>ясмин</th>\n",
       "      <th>ясно</th>\n",
       "      <th>ясность</th>\n",
       "      <th>ясный</th>\n",
       "      <th>яхта</th>\n",
       "      <th>ящерица</th>\n",
       "      <th>ящик</th>\n",
       "      <th>ящичек</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 14110 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   after  again  ahh  all  and  are  au  ban  bay  behind   ...    ярмарка  \\\n",
       "0      0      0    0    0    0    0   0    0    0       0   ...          0   \n",
       "1      0      0    0    0    0    0   0    0    0       0   ...          0   \n",
       "2      0      0    0    0    0    0   0    0    0       0   ...          1   \n",
       "3      0      0    0    0    0    0   0    0    0       0   ...          0   \n",
       "4      0      0    0    0    0    0   0    0    0       0   ...          0   \n",
       "\n",
       "   ярость  ясмин  ясно  ясность  ясный  яхта  ящерица  ящик  ящичек  \n",
       "0       0      0     0        0      0     0        1     0       0  \n",
       "1       0      0     0        0      0     0        0     0       0  \n",
       "2       0      0     0        0      0     0        0     0       0  \n",
       "3       0      0     1        0      0     0        0     0       0  \n",
       "4       0      0     0        0      0     0        0     0       0  \n",
       "\n",
       "[5 rows x 14110 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(165, 14110)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from luqum.parser import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def operations(tree):\n",
    "    if isinstance(tree, Group):\n",
    "        return operations(tree.children[0])\n",
    "    elif hasattr(tree, 'op'):\n",
    "        if tree.op == 'AND':\n",
    "            res = set(range(len(df['росс'])))\n",
    "            for el in tree.children:\n",
    "                f = operations(el)\n",
    "                res = res & f\n",
    "            print('RES', res)\n",
    "            return res\n",
    "        elif tree.op == 'OR':# ИЛИ\n",
    "            res = set(range(len(df['росс'])))\n",
    "            for el in tree.children:\n",
    "                f = operations(el)\n",
    "                res = res | f\n",
    "            print('RES', res)\n",
    "            return res\n",
    "        elif tree.op == 'NOT ':\n",
    "            word = lemmatize(tree.children[0].value.lower())\n",
    "            res = set(range(len(df['росс']))) - set(np.where(df[word[0]] > 0)[0])\n",
    "            print('RES', res)\n",
    "            return res\n",
    "    elif isinstance(tree, Word):\n",
    "        word = lemmatize(tree.value.lower()).strip()\n",
    "        #print(word)\n",
    "        if word in words:\n",
    "            return set(np.where(df[word] > 0)[0])\n",
    "        else:\n",
    "            #print(word, 'нет в словаре')\n",
    "            return set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Моника AND Фиби AND Рэйчел AND Чендлер AND Джои AND Росс\n",
      "моника\n",
      "фиби\n",
      "рэйчел\n",
      "чендлер\n",
      "джой\n",
      "росс\n",
      "RES {0, 3, 6, 8, 13, 21, 53}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['1x01', '1x04', '1x07', '1x09', '1x14']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boolean_search('Моника & Фиби & Рэйчел & Чендлер & Джои & Росс')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_text = [\n",
    "    'Моника & Фиби & Рэйчел & Чендлер & Джои & Росс',\n",
    "    '(Моника ИЛИ Фиби) & Рэйчел & (Чендлер ИЛИ Джои) & Росс', \n",
    "    '(НЕ Моника) & Фиби & Рэйчел & Чендлер & Джои & (НЕ Росс)'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boolean_search(search) -> list:\n",
    "    \"\"\"\n",
    "    Produces a Boolean search according with the term-document matrix\n",
    "    :return: list of first 5 relevant documents\n",
    "    \"\"\"\n",
    "    search = search.replace('&','AND').replace('НЕ','NOT').replace('ИЛИ','OR')\n",
    "    tree = parser.parse(search)\n",
    "    print(tree)\n",
    "    try:\n",
    "        return [re.search('([0-9]+x[0-9]+)', files_list[element]).group(1) for element in list(operations(tree))[0:5]]\n",
    "    except:\n",
    "        return [re.search('([0-9]+x[0-9]+)', files_list[element]).group(1) for element in list(operations(tree))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for search in input_text:\n",
    "    print(boolean_search(search))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Совет для построения обратного индекса: \n",
    "> В качестве словаря используйте ``` defaultdict ``` из модуля collections   \n",
    "Так можно избежать конструкции ``` dict.setdefault(key, default=None) ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inverted_index(df) -> dict:\n",
    "    \"\"\"\n",
    "    Create inverted index by input doc collection\n",
    "    :return: inverted index\n",
    "    \"\"\"\n",
    "    #d = {}\n",
    "    files = []\n",
    "    for word in df:\n",
    "        files.append(np.where(df[word] > 0)[0])\n",
    "    index = pd.DataFrame(data={'Слово': words, 'Серии': files})\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = inverted_index(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Серии</th>\n",
       "      <th>Слово</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[149]</td>\n",
       "      <td>after</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[110]</td>\n",
       "      <td>again</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[93]</td>\n",
       "      <td>ahh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[109, 116]</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[67, 134]</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Серии  Слово\n",
       "0       [149]  after\n",
       "1       [110]  again\n",
       "2        [93]    ahh\n",
       "3  [109, 116]    all\n",
       "4   [67, 134]    and"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>after</th>\n",
       "      <th>again</th>\n",
       "      <th>ahh</th>\n",
       "      <th>all</th>\n",
       "      <th>and</th>\n",
       "      <th>are</th>\n",
       "      <th>au</th>\n",
       "      <th>ban</th>\n",
       "      <th>bay</th>\n",
       "      <th>behind</th>\n",
       "      <th>...</th>\n",
       "      <th>ярмарка</th>\n",
       "      <th>ярость</th>\n",
       "      <th>ясмин</th>\n",
       "      <th>ясно</th>\n",
       "      <th>ясность</th>\n",
       "      <th>ясный</th>\n",
       "      <th>яхта</th>\n",
       "      <th>ящерица</th>\n",
       "      <th>ящик</th>\n",
       "      <th>ящичек</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 14110 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   after  again  ahh  all  and  are  au  ban  bay  behind   ...    ярмарка  \\\n",
       "0      0      0    0    0    0    0   0    0    0       0   ...          0   \n",
       "1      0      0    0    0    0    0   0    0    0       0   ...          0   \n",
       "2      0      0    0    0    0    0   0    0    0       0   ...          1   \n",
       "3      0      0    0    0    0    0   0    0    0       0   ...          0   \n",
       "4      0      0    0    0    0    0   0    0    0       0   ...          0   \n",
       "\n",
       "   ярость  ясмин  ясно  ясность  ясный  яхта  ящерица  ящик  ящичек  \n",
       "0       0      0     0        0      0     0        1     0       0  \n",
       "1       0      0     0        0      0     0        0     0       0  \n",
       "2       0      0     0        0      0     0        0     0       0  \n",
       "3       0      0     1        0      0     0        0     0       0  \n",
       "4       0      0     0        0      0     0        0     0       0  \n",
       "\n",
       "[5 rows x 14110 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>155</th>\n",
       "      <th>156</th>\n",
       "      <th>157</th>\n",
       "      <th>158</th>\n",
       "      <th>159</th>\n",
       "      <th>160</th>\n",
       "      <th>161</th>\n",
       "      <th>162</th>\n",
       "      <th>163</th>\n",
       "      <th>164</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>after</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>again</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ahh</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 165 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3    4    5    6    7    8    9   ...   155  156  157  \\\n",
       "after    0    0    0    0    0    0    0    0    0    0 ...     0    0    0   \n",
       "again    0    0    0    0    0    0    0    0    0    0 ...     0    0    0   \n",
       "ahh      0    0    0    0    0    0    0    0    0    0 ...     0    0    0   \n",
       "all      0    0    0    0    0    0    0    0    0    0 ...     0    0    0   \n",
       "and      0    0    0    0    0    0    0    0    0    0 ...     0    0    0   \n",
       "\n",
       "       158  159  160  161  162  163  164  \n",
       "after    0    0    0    0    0    0    0  \n",
       "again    0    0    0    0    0    0    0  \n",
       "ahh      0    0    0    0    0    0    0  \n",
       "all      0    0    0    0    0    0    0  \n",
       "and      0    0    0    0    0    0    0  \n",
       "\n",
       "[5 rows x 165 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### какое слово является самым частотным?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = {}\n",
    "for word in df:\n",
    "    frq = sum(df[word])\n",
    "    d[word] = frq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "sorted_d = sorted(d.items(), key=operator.itemgetter(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Самое частотное слово - \" ты \"( 11194 вхождений )\n"
     ]
    }
   ],
   "source": [
    "sorted_d[-1]\n",
    "print('Самое частотное слово - \"', sorted_d[-1][0], '\"(', sorted_d[-1][1], 'вхождений )')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### какое самым редким?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Одно из самых редких слов \" after \"( 1 вхождений )\n"
     ]
    }
   ],
   "source": [
    "print('Одно из самых редких слов \"', sorted_d[0][0], '\"(', sorted_d[0][1], 'вхождений )')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### какой набор слов есть во всех документах коллекции?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "быть, весь, все, да, давать, думать, если, еще, знать, как, мой, мочь, мы, на, не, нет, но, ну, он, она, они, просто, сказать, так, такой, то, ты, хорошо, хотеть, что, это, этот\n"
     ]
    }
   ],
   "source": [
    "list_w = []\n",
    "for word in df:\n",
    "    if len(np.where(df[word] > 0)[0]) == 165:\n",
    "        list_w.append(word)\n",
    "print(', '.join(list_w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### какой сезон был самым популярным у Чендлера? у Моники?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>чендлер</th>\n",
       "      <th>моника</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>№ сезона</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>77</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>104</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>139</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>150</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>144</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          чендлер  моника\n",
       "№ сезона                 \n",
       "1              57      57\n",
       "2              53      78\n",
       "3              77      70\n",
       "4             104      73\n",
       "5             139     131\n",
       "6             150     126\n",
       "7             144     159"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seasons = [re.search('([0-9]+)x[0-9]+', el).group(1) for el in files_list]\n",
    "from itertools import groupby\n",
    "df['№ сезона'] = seasons\n",
    "df[['чендлер', '№ сезона', 'моника']].groupby(['№ сезона']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "У Чендлера самым популярным сезоном был 6, у Моники - 7\n"
     ]
    }
   ],
   "source": [
    "print('У Чендлера самым популярным сезоном был 6, у Моники - 7')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### кто из главных героев статистически самый популярный?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = []\n",
    "for word in ['моника', 'рэйчел', 'фиби', 'чендлер','росс','джой']:\n",
    "    vals.append(sum(df[word]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x10c8d97f0>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEKCAYAAAAb7IIBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10ca7ee48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df1 = pd.DataFrame({'герой':['моника', 'рэйчел', 'фиби', 'чендлер','росс','джой'], 'частотность':vals})\n",
    "df1.plot.bar(x='герой', y='частотность', rot=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью обратного индекса произведите следующую аналитику:  \n",
    "\n",
    "1) общая аналитика\n",
    "- какое слово является самым частотным?\n",
    "- какое самым редким?\n",
    "- какой набор слов есть во всех документах коллекции?\n",
    "\n",
    "2) частота встречаемости имен главных героев в каждом сезоне      \n",
    "- какой сезон был самым популярным у Чендлера? у Моники?   \n",
    "- кто из главных героев статистически самый популярный? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функция ранжирования Okapi BM25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для обратного индекса есть общепринятая формула для ранжирования *Okapi best match 25* ([Okapi BM25](https://ru.wikipedia.org/wiki/Okapi_BM25)).    \n",
    "Пусть дан запрос $Q$, содержащий слова  $q_1, ... , q_n$, тогда функция BM25 даёт следующую оценку релевантности документа $D$ запросу $Q$:\n",
    "\n",
    "$$ score(D, Q) = \\sum_{i}^{n} \\text{IDF}(q_i)*\\frac{(k_1+1)*f(q_i,D)}{f(q_i,D)+k_1(1-b+b\\frac{|D|}{avgdl})} $$ \n",
    "где   \n",
    ">$f(q_i,D)$ - частота слова $q_i$ в документе $D$ (TF)       \n",
    "$|D|$ - длина документа (количество слов в нём)   \n",
    "*avgdl* — средняя длина документа в коллекции    \n",
    "$k_1$ и $b$ — свободные коэффициенты, обычно их выбирают как $k_1$=2.0 и $b$=0.75   \n",
    "$$$$\n",
    "$\\text{IDF}(q_i)$ есть обратная документная частота (IDF) слова $q_i$: \n",
    "$$\\text{IDF}(q_i) = \\log\\frac{N-n(q_i)+0.5}{n(q_i)+0.5},$$\n",
    ">> где $N$ - общее количество документов в коллекции   \n",
    "$n(q_i)$ — количество документов, содержащих $q_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### реализуйте эту функцию ранжирования \n",
    "from math import log\n",
    "\n",
    "k1 = 2.0\n",
    "b = 0.75\n",
    "avgdl = round(sum([len(el) for el in files_list])/len(files_list))\n",
    "N = len(files_list)\n",
    "\n",
    "def score_BM25(qf, dl, avgdl, k1, b, N, n) -> float:\n",
    "    \"\"\"\n",
    "    Compute similarity score between search query and documents from collection\n",
    "    :return: score\n",
    "    \"\"\"\n",
    "    score = math.log((N-n+0.5)/(n+0.5)) * (k1+1)*qf/(qf+k1*(1-b+b*(dl/avgdl)))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Задача__:    \n",
    "напишите функцию, которая сортирует поисковую выдачу для любого входящего запроса согласно метрике *Okapi BM25*.    \n",
    "Выведите 10 первых результатов и их скор по запросу **рождественские каникулы**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sim(lemma, inverted_index) -> float:\n",
    "    \"\"\"\n",
    "    Compute similarity score between word in search query and all document  from collection\n",
    "    :return: score\n",
    "    \"\"\"\n",
    "    doc_list = df[lemma]\n",
    "    n = len(np.where(df[word] > 0)[0])\n",
    "    relevance_dict = []\n",
    "    for i, doc in enumerate(doc_list):\n",
    "        qf = doc/len(files_list[i])\n",
    "        dl = len(files_list[i])\n",
    "        relevance_dict.append(score_BM25(qf, dl, avgdl, k1, b, N, n))\n",
    "    return relevance_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_search_result(query) -> list:\n",
    "    \"\"\"\n",
    "    Compute sim score between search query and all documents in collection\n",
    "    Collect as pair (doc_id, score)\n",
    "    :param query: input text\n",
    "    :return: list of lists with (doc_id, score)\n",
    "    \"\"\"\n",
    "    query = lemmatize(query).split()\n",
    "    res = [0] * len(files_list)\n",
    "    for word in query:\n",
    "        relevance_dict = compute_sim(word, inverted_index)\n",
    "        res = [x + y for x, y in zip(res, relevance_dict)]\n",
    "    d = {}\n",
    "    for i, num in enumerate(res):\n",
    "        d[i] = num\n",
    "    return sorted(d.items(), key=operator.itemgetter(1), reverse=True)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7x10 - The One With The Holiday Armadillo 0.39286475145086625\n",
      "6x19 - The One With Joey's Fridge 0.3349870549300526\n",
      "3x10 - The One Where Rachel Quits 0.2805161268001936\n",
      "2x09 - The One With Phoebe's Dad 0.17283539922574218\n",
      "4x03 - The One With The 'Cuffs 0.11981819934653669\n",
      "1x16 - The One With Two Parts (1) 0.11387103481662725\n",
      "1x17 - The One With Two Parts (2) 0.11387103481662725\n",
      "4x10 - The One With The Girl From Poughkeepsie 0.09261545073530975\n",
      "6x12 - The One With The Joke 0.062359319987906975\n",
      "6x10 - The One With The Routine 0.059195210728478304\n"
     ]
    }
   ],
   "source": [
    "for x in get_search_result('рождественские каникулы'):\n",
    "    print(re.search('([0-9]+x[0-9].+?).ru', files_list[x[0]]).group(1), x[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
