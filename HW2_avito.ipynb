{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### –°—Å—ã–ª–∫–∞ –Ω–∞ –∫–æ—Ä–ø—É—Å: https://drive.google.com/drive/u/0/folders/1BMbFqjGr-QsH5YX-mPd9P3653qf7MI-a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "import random\n",
    "import time\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import re\n",
    "import unicodedata\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bs(url):\n",
    "    req = requests.get(url)\n",
    "    html= req.text\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = unicodedata.normalize(\"NFKD\", text)\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    text = text.strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_info(text):\n",
    "    text = re.sub('(\\n)+', ' ', text)\n",
    "    text = unicodedata.normalize(\"NFKD\", text)\n",
    "    text = re.sub('–ê–¥—Ä–µ—Å|–ö–æ–º–ø–∞–Ω–∏—è|–ö–æ–Ω—Ç–∞–∫—Ç–Ω–æ–µ –ª–∏—Ü–æ', ' ', text)\n",
    "    text = re.sub('( ){2,}', ', ', text)\n",
    "    text = text.strip()[2:-1]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def try_except(soup, _tag, _class, _group='class'):\n",
    "    try:\n",
    "        item = soup.find(_tag, attrs={_group:_class}).text\n",
    "    except:\n",
    "        item = 'NAN'\n",
    "    return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_info(soup, url):\n",
    "    text = ''\n",
    "    title = try_except(soup, 'span', 'title-info-title-text')\n",
    "    num_date = try_except(soup, 'div', 'title-info-metadata-item')\n",
    "    price = try_except(soup, 'span', 'price-value-string js-price-value-string')\n",
    "    info_author = try_except(soup, 'div', 'item-view-seller-info')\n",
    "    dog_params = try_except(soup, 'div', 'item-params')\n",
    "    dog_location = try_except(soup, 'div', 'item-map-location')\n",
    "    dog_description = try_except(soup, 'div', 'description', _group='itemprop')\n",
    "    text = '–ù–∞–∑–≤–∞–Ω–∏–µ: ' + clean(title) + '\\n' + \\\n",
    "    '–ù–æ–º–µ—Ä –∏ –¥–∞—Ç–∞ –æ–±—ä—è–≤–ª–µ–Ω–∏—è: ' + clean(num_date) + '\\n' + \\\n",
    "    '–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –∞–≤—Ç–æ—Ä–µ: ' + clean_info(info_author) + '\\n' + \\\n",
    "    '–ê–¥—Ä–µ—Å —Å–æ–±–∞–∫–∏: ' + clean(dog_location).replace('–ê–¥—Ä–µ—Å: ', '').replace(' –ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å –∫–∞—Ä—Ç—É', '') + '\\n' + \\\n",
    "    clean(dog_params) + '\\n' + \\\n",
    "    '–¶–µ–Ω–∞: ' + clean(price) + '\\n' + \\\n",
    "    '–û–ø–∏—Å–∞–Ω–∏–µ —Å–æ–±–∞–∫–∏: ' + clean(dog_description) + '\\n' + \\\n",
    "    'URL: ' + url\n",
    "    return text"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def find_info(soup, url):\n",
    "    dict_info = {}\n",
    "    text = ''\n",
    "    title = try_except(soup, 'span', 'title-info-title-text')\n",
    "    num_date = try_except(soup, 'div', 'title-info-metadata-item')\n",
    "    price = try_except(soup, 'span', 'price-value-string js-price-value-string')\n",
    "    info_author = try_except(soup, 'div', 'item-view-seller-info')\n",
    "    dog_params = try_except(soup, 'div', 'item-params')\n",
    "    dog_location = try_except(soup, 'div', 'item-map-location')\n",
    "    dog_description = try_except(soup, 'div', 'description', _group='itemprop')\n",
    "    dict_info['–ù–∞–∑–≤–∞–Ω–∏–µ'] = clean(title)\n",
    "    dict_info['–ù–æ–º–µ—Ä –∏ –¥–∞—Ç–∞ –æ–±—ä—è–≤–ª–µ–Ω–∏—è'] = clean(num_date)\n",
    "    dict_info['–¶–µ–Ω–∞'] = clean(price)\n",
    "    dict_info['–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –∞–≤—Ç–æ—Ä–µ'] = clean_info(info_author)\n",
    "    dict_info['–ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–æ–±–∞–∫–∏'] = clean(dog_params)\n",
    "    dict_info['–ê–¥—Ä–µ—Å —Å–æ–±–∞–∫–∏'] = clean(dog_location)\n",
    "    dict_info['–û–ø–∏—Å–∞–Ω–∏–µ —Å–æ–±–∞–∫–∏'] = clean(dog_description)\n",
    "    text = '–ù–∞–∑–≤–∞–Ω–∏–µ: ' + dict_info['–ù–∞–∑–≤–∞–Ω–∏–µ'] + '\\n' + \\\n",
    "    '–ù–æ–º–µ—Ä –∏ –¥–∞—Ç–∞ –æ–±—ä—è–≤–ª–µ–Ω–∏—è: ' + dict_info['–ù–æ–º–µ—Ä –∏ –¥–∞—Ç–∞ –æ–±—ä—è–≤–ª–µ–Ω–∏—è'] + '\\n' + \\\n",
    "    '–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –∞–≤—Ç–æ—Ä–µ: ' + dict_info['–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –∞–≤—Ç–æ—Ä–µ'] + '\\n' + \\\n",
    "    '–ê–¥—Ä–µ—Å —Å–æ–±–∞–∫–∏: ' + dict_info['–ê–¥—Ä–µ—Å —Å–æ–±–∞–∫–∏'].replace('–ê–¥—Ä–µ—Å: ', '').replace(' –ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å –∫–∞—Ä—Ç—É', '') + '\\n' + \\\n",
    "    dict_info['–ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–æ–±–∞–∫–∏'] + '\\n' + \\\n",
    "    '–¶–µ–Ω–∞: ' + dict_info['–¶–µ–Ω–∞'] + '\\n' + \\\n",
    "    '–û–ø–∏—Å–∞–Ω–∏–µ —Å–æ–±–∞–∫–∏: ' + dict_info['–û–ø–∏—Å–∞–Ω–∏–µ —Å–æ–±–∞–∫–∏'] + '\\n' + \\\n",
    "    'URL: ' + url\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_file(text, name):\n",
    "    name = name.replace('/', '$')#.replace(':', '$')\n",
    "    file = open('/Users/irene/Downloads/IR/avito_dogs/' + name + \".txt\", \"w\") \n",
    "    file.write(text)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### –ü—Ä–∏–º–µ—Ä"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_of_article = '/sankt-peterburg/sobaki/shpits_1602362094'\n",
    "begin = 'https://www.avito.ru'\n",
    "clean_url = begin + url_of_article\n",
    "soup_page = bs(clean_url)\n",
    "text = find_info(soup_page, clean_url)\n",
    "write_file(text, url_of_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'–ù–∞–∑–≤–∞–Ω–∏–µ: –®–ø–∏—Ü\\n–ù–æ–º–µ—Ä –∏ –¥–∞—Ç–∞ –æ–±—ä—è–≤–ª–µ–Ω–∏—è: No 1602362094, —Ä–∞–∑–º–µ—â–µ–Ω–æ –≤—á–µ—Ä–∞ –≤ 12:50\\n–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –∞–≤—Ç–æ—Ä–µ: –ú–∞–ª–µ–Ω—å–∫–∏–π –ê–Ω–≥–µ–ª, –ù–∞ –ê–≤–∏—Ç–æ c –∞–≤–≥—É—Å—Ç–∞ 2011, –ó–∞–≤–µ—Ä—à–µ–Ω–æ 200 –æ–±—ä—è–≤–ª–µ–Ω–∏–π, –ü—É–±–ª–∏—á–Ω—ã–π –ø—Ä–æ—Ñ–∏–ª—å, 6 –æ–±—ä—è–≤–ª–µ–Ω–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –°–≤–µ—Ç–ª–∞–Ω–∞, –°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥, –º. –ü–∞—Ä–∫ –ü–æ–±–µ–¥—ã\\n–ê–¥—Ä–µ—Å —Å–æ–±–∞–∫–∏: –°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥, –º. –ü–∞—Ä–∫ –ü–æ–±–µ–¥—ã\\n–ü–æ—Ä–æ–¥–∞: —à–ø–∏—Ü\\n–¶–µ–Ω–∞: 25 000 ‚ÇΩ\\n–û–ø–∏—Å–∞–Ω–∏–µ —Å–æ–±–∞–∫–∏: –©–µ–Ω–∫–∏ –ø–æ–º–µ—Ä–∞–Ω—Å–∫–æ–≥–æ —à–ø–∏—Ü–∞ 2–º–µ—Å., –¥–æ–∫—É–º–µ–Ω—Ç—ã –†–ö–§, –ø—Ä–∏–≤–∏—Ç—ã –ø–æ –≤–æ–∑—Ä–∞—Å—Ç—É. –ü–∞–ø–∞ üíØ% –ê–º–µ—Ä–∏–∫–∞ –∏ –º–∞–º–∞ –∂–∏–≤—É—Ç –≤ –æ–¥–Ω–æ–º –¥–æ–º–µ.–ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–∏ –∑–∞–≤–æ–¥—á–∏–∫–∞ –ø–æ –≤–æ–ø—Ä–æ—Å–∞–º —É—Ö–æ–¥–∞ –∏ –≤–æ—Å–ø–∏—Ç–∞–Ω–∏—è –ø–æ–∂–∏–∑–Ω–µ–Ω–Ω–æ. –î–ò–ê–ü–ê–ó–û–ù –¶–ï–ù.\\nURL: https://www.avito.ru/sankt-peterburg/sobaki/shpits_1602362094'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### –í—ã–∫–∞—á–∏–≤–∞–µ–º –∫–æ—Ä–ø—É—Å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in tqdm(range(1, 101)):\n",
    "    sec1 = random.uniform(0, 10)\n",
    "    url = 'https://www.avito.ru/rossiya/sobaki?p=' + str(x) + '&view=list'\n",
    "    soup = bs(url)\n",
    "    articles = soup.find_all('a', attrs={'class':'description-title-link'})\n",
    "    time.sleep(sec1)\n",
    "    for item in articles:\n",
    "        url_of_article = item.get('href')\n",
    "        begin = 'https://www.avito.ru'\n",
    "        clean_url = begin + url_of_article\n",
    "        soup_page = bs(clean_url)\n",
    "        text = find_info(soup_page, clean_url)\n",
    "        write_file(text, url_of_article)\n",
    "        sec2 = random.uniform(0, 10)\n",
    "        time.sleep(sec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
